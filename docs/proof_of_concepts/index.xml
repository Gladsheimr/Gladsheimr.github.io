<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Glaðsheimr</title>
    <link>/docs/proof_of_concepts/</link>
    <description>Recent content on Glaðsheimr</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/docs/proof_of_concepts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Proof of Concepts</title>
      <link>/docs/proof_of_concepts/audio-fpga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/proof_of_concepts/audio-fpga/</guid>
      <description>Audio, Arduino and FPGA In this proof of concept we want to showcase how multiple devices can be used to build the an application (detect keywords in sounds).
Overview The application will replicate another TinyML proof of concept that was demonstrated in Tensorflow Lite Micro. The PoC infers command words on PDM (Pulse Density Modulation) signals. The code and documentation for this application is available on the Tensorflow github repo.</description>
    </item>
    
  </channel>
</rss>